Here are some possible machine learning engineer interview questions. 

1. What is machine learning?
2. How is KNN different from k-means clustering?
3. Why is Naive Bayes so 'naive'?
4. How is True Positive Rate and Recall related? 
5. What is the trade-off between bias and variance?
6. Explain what a ROC curve is?
7. Define precision and recall?
8. What is the difference between covariance and correlation?
9. What is Bayes Theorem?
10. What's the difference between probability and likelihood?
11. When is Ridge regression favorable over Lasso regression?
12. What is convex hull?
13. What's "kernel trick" and why is it useful?
14. What Deep Learning is exactly?
15. Which is more important to you - model accuracy, or model performance?
16. What cross-validation technique would you use on a time series dataset?
17. What's the difference between a generative and discriminative model?
18. Where do you usually source data-sets?
19. When should you use classification over regression?
20. What are your favorite use cases of machine learning models?

R:
1. In short machine learning is the study of computer algorithms that improve automatically through experience. 
2. KNN is a supervised machine learning while K-means is an unsupervised machine learning. KNN is a classification or
regression ML algorithm while K-means is a clustering ML algo. KNN is a lazy learner, K-means is an eager learner. An eager
learner has a model fitting that means a training step but a lazy learner does not have a training phase.
3. Naive Bayes (NB) is 'naive' because it makes assumption that features of a measurement are independent of each other.
4. Recall = True Positive / (True Positive + False Negative)
5. If our model is too simple and has very few parameters then it may have high bias and low variance. On the other hand if 
our model has large number of parameters then it's going to have high variance and low bias. We need to find the right balance
without underfitting and overfitting the data. 
6. A ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination
threshold is varied. 
7. Precision is the fraction of relevant instances among the retrieved instances, while recall is the fraction of the total
amount of relevant instances that were actually retrieved.
8. Correlation is when the change in one item may result in the change in the another item. On the other hand, covariance is 
when two items vary together. 
9. Bayes' theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the 
event. P(A|B) = P(B|A)*P(A)/P(B)
10. Probability refers to the occurrence of future events, while a likelihood refers to past events with known outcomes.
11. By using either you insert some prior knowledge into the approach. With Ridge you are saying that all the features are 
important, but that you want to avoid the importances blowing up. With LASSO you are saying that the target depends on only
some small subsets of the inputs, but you do not know which ones. 
12. The convex hull of a shape is the smallest convex set that contains it. 
13. Kernel methods owe their name to the use of kernel functions, which enable them to operate in a high-dimensional feature
space without computing the coordinates of the data in that space, but rather by simply computing the inner products between
the images of all pairs of data in the feature space. This operation is often computationally cheaper and is called "kernel
trick". 
14. Deep Learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher 
level features from the raw input.
15. The best accuracy is 100% indicating that all the predictions are correct. For an imbalanced dataset, accuracy is not a 
valid measure of model performance. For a dataset where the default rate is 5%, even if all the records are predicted as 0, 
the model will still have an accuracy of 95%. Model performance is a better indicator than accuracy as accuracy does not 
necessarily say how good the model is. 
16. 
17. A generative algorithm models how the data was generated in order to categorize a signal. A discriminative algorithm does
not care about how the data was generated, it simply categorizes a given signal.
18. Some well known data-sets sources are: Kaggle Datasets, Amazon Datasets, UCL Machine Learning Repository, Google's Datasets
Search Engine, Microsoft Datasets.
19. Regression: if your outcome of interest is a real or continous value; classification: if your outcome of interest is 
discrete or categorical
20. Detecting Fake News, Face Authentication, Content Recommendation
